[supported_formats]
types = ['dataframe', 'text', 'array', 'null']

[backend]
default = 'pandas'


[text]
model = ['CountVectorizer', 'LatentDirichletAllocation']
corpus = 'minipedia'
corpus_config = None

[CountVectorizer]
stop_words = 'english'
lowercase = True
max_df = 0.25
min_df = 0.1
strip_accents = 'unicode'

[HashingVectorizer]
stop_words = 'english'
lowercase = True
max_df = 0.25
min_df = 0.1
strip_accents = 'unicode'

[TfidfTransformer]
norm = 'l2'
use_idf = True
smooth_idf = True
sublinear_tf = False

[TfidfVectorizer]
stop_words = 'english'
lowercase = True
max_df = 0.25
min_df = 0.1
strip_accents = 'unicode'

[DictionaryLearning]
n_components = 50

[FactorAnalysis]
n_components = 50

[FastICA]
n_components = 50

[IncrementalPCA]
n_components = 50

[KernelPCA]
n_components = 50

[LatentDirichletAllocation]
n_components = 50
learning_method = 'online'

[MiniBatchDictionaryLearning]
n_components = 50

[MiniBatchSparsePCA]
n_components = 50

[NMF]
n_components = 50

[PCA]
n_components = 50

[SparsePCA]
n_components = 50

[TruncatedSVD]
n_components = 50

# Sentence-Transformers Models (Modern NLP)
[SentenceTransformer]
__model = 'all-MiniLM-L6-v2'

[all-MiniLM-L6-v2]
# Fast, general-purpose sentence embeddings
# Good for: similarity search, clustering, information retrieval

[all-mpnet-base-v2]
# High-quality sentence embeddings
# Good for: semantic similarity, paraphrase detection

[paraphrase-MiniLM-L6-v2]
# Optimized for paraphrase detection
# Good for: duplicate detection, content deduplication

[all-distilroberta-v1]
# Balanced performance and speed
# Good for: general text understanding tasks

[impute]
model = 'IterativeImputer'

[SimpleImputer]
missing_values = np.nan
strategy = 'mean'

[IterativeImputer]
missing_values = np.nan
initial_strategy = 'mean'

[KNNImputer]
missing_values = np.nan
weights = 'distance'

[interpolate]
method = 'linear'
limit_direction = 'both'

[data]
homedir = os.getenv('HOME')
datadir = os.path.join(%(homedir)s, '.datawrangler', 'data', '')